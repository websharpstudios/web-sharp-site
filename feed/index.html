<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/" xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/">

	<channel>
		<title>WebSharp</title>
		<atom:link href="/feed/" rel="self" type="application/rss+xml" />
		<link>http://www.websharpstudios.com</link>
		<description>Data Solutions Provider</description>
		<lastBuildDate>Mon, 22 Mar 2021 18:08:03 +0000</lastBuildDate>
		<language>en-US</language>
		<sy:updatePeriod>
			hourly </sy:updatePeriod>
		<sy:updateFrequency>
			1 </sy:updateFrequency>

		<item>
			<title>Guitar, Drums, Cat?: Where is NSynth taking music?</title>
			<link>/guitar-drums-cat-where-is-nsynth-taking-music/</link>

			<dc:creator>
				<![CDATA[Lisa]]>
			</dc:creator>
			<pubDate>Fri, 05 Jan 2021 15:46:46 \+0000</pubDate>
			<category>
				<![CDATA[Artificial Intelligence]]>
			</category>
			<category>
				<![CDATA[Audio]]>
			</category>
			<category>
				<![CDATA[Machine Learning]]>
			</category>
			<category>
				<![CDATA[featured2]]>
			</category>
			<guid isPermaLink="false">http://websharpstudios.com/?p=6014</guid>

			<description>
				<![CDATA[<p>When George Beauchamp designed the first electric guitar in 1931 he probably never envisaged young musicians manipulating frequencies and feedback as part of music. But this is the beauty of...  </p>
<div class="read-more"><a class="excerpt-read-more" href="/guitar-drums-cat-where-is-nsynth-taking-music/" title="Continue reading Guitar, Drums, Cat?: Where is NSynth taking music?">Read more<i class="fa fa-angle-right"></i></a></div>
<p>The post <a rel="nofollow" href="/guitar-drums-cat-where-is-nsynth-taking-music/">Guitar, Drums, Cat?: Where is NSynth taking music?</a> appeared first on <a rel="nofollow" href="http://www.websharpstudios.com">WebSharp</a>.</p>
]]>
			</description>
			<content:encoded>
				<![CDATA[<p>When George Beauchamp designed the first electric guitar in 1931 he probably never envisaged young musicians manipulating frequencies and feedback as part of music. But this is the beauty of musical evolution.</p>
<p>The NSynth sound maker (part of Google&#8217;s Magenta project) is a truly novel approach to sound. Conceptually &#8220;NSynth uses deep neural networks to generate sounds at the level of individual samples. Learning directly from data, NSynth provides artists with intuitive control over timbre and dynamics and the ability to explore new sounds that would be difficult or impossible to produce with a hand-tuned synthesizer.&#8221;</p>
<p>Practically, this means that you could blend a trombone and a cow with varying degrees of each to create a whole new &#8216;instrument&#8217;. Although it is fun to tinker with, you should recognize that from a musician&#8217;s perspective, this could mean a complete rethinking of the compartmentalization of a musician. It may be the case that you are no longer just a guitarist but rather a&#8230; well, we&#8217;ll come up with something.</p>
<p><iframe width="560" height="315" src="https://www.youtube.com/embed/AaALLWQmCdI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></p>
<p>The NSynth system was trained through the development of an audio dataset containing 305,979 musical notes, each with a unique pitch, timbre, and envelope. This dataset has been made available for download (<a href="https://magenta.tensorflow.org/datasets/nsynth" target="_blank" rel="nofollow noopener noreferrer">https://magenta.tensorflow.org/datasets/nsynth</a>).</p>
<p>If you&#8217;d like to play around with the system it is available at <a href="https://experiments.withwebsharpstudios.com/ai/sound-maker/view/" target="_blank" rel="nofollow noopener noreferrer">https://experiments.withwebsharpstudios.com/ai/sound-maker/view/</a>. Also, to see what other people are doing it check out Andrew Huang&#8217;s demo on <a href="https://www.youtube.com/watch?v=AaALLWQmCdI&amp;t=333s" target="_blank" rel="nofollow noopener noreferrer">https://www.youtube.com/watch?v=AaALLWQmCdI&amp;t=333s</a>.</p>
<p>The post <a rel="nofollow" href="/guitar-drums-cat-where-is-nsynth-taking-music/">Guitar, Drums, Cat?: Where is NSynth taking music?</a> appeared first on <a rel="nofollow" href="http://www.websharpstudios.com">WebSharp</a>.</p>
]]>
			</content:encoded>



		</item>
		<item>
			<title>AI in Music: The End of Human Creativity?</title>
			<link>/ai-empowered-ehr/</link>

			<dc:creator>
				<![CDATA[Lisa]]>
			</dc:creator>
			<pubDate>Fri, 10 Nov 2020 15:45:37 +0000</pubDate>
			<category>
				<![CDATA[Artificial Intelligence]]>
			</category>
			<category>
				<![CDATA[Audio]]>
			</category>
			<category>
				<![CDATA[Machine Learning]]>
			</category>
			<category>
				<![CDATA[featured1]]>
			</category>
			<guid isPermaLink="false">http://websharpstudios.com/?p=6011</guid>

			<description>
				<![CDATA[<p>Music has for a long time been perceived as one of the bastions of creativity. However, in our process of developing Auricle, an AI music composition platform many ethical questions...  </p>
<div class="read-more"><a href="/our-services/ai-empowered-ehr/" title="AI Empowered Health Records: Reducing the Burden on Providers?" class="vc_gitem-link vc-zone-link"></a></div>
<p>The post <a href="/our-services/ai-empowered-ehr/" title="AI Empowered Health Records: Reducing the Burden on Providers?" class="vc_gitem-link vc-zone-link"></a>.</p>
]]>
			</description>
			<content:encoded>
				<![CDATA[<p>Music has for a long time been perceived as one of the bastions of creativity. However, in our process of developing Auricle, an AI music composition platform many ethical questions have started cropping up. Is this the end for composers and artists? Are we depriving a generation of creativity?</p>
<p>Douglas Eck of Google’s Magenta project has been considerably clear that its objective is to enhance and push the boundaries of the creative experience, not replace it. Likewise, Aiva, a platform that is able to produce western classical compositions in minutes still requires human input with regards to orchestration and musical production and its creators surprisingly envisage human collaboration rather than replacement.</p>
<p>So if deep learning algorithms can teach systems to develop music, what is left for composers to do? Well at this stage, there’s a lot. Many platforms are still highly dependent on human input in terms of the creative aspect but that will naturally begin to change with the AI systems learning more from user habits.</p>
<p>Like many industries around the world that have seen change due to automation, musicians will need to adapt to the technological advancements. This won&#8217;t mean a complete replacement but rest assured the bar is being raised.</p>
<p>On the other hand we should appreciate that music has always been tied in to an expression of feeling which is a culmination of collective experiences that causes the musician to strum in that particular way or press a key with that much passion. AI music systems have not explored this aspect of creativity and for now, it remains uniquely human.</p>
<p>The post <a href="/our-services/ai-empowered-ehr/" title="AI Empowered Health Records: Reducing the Burden on Providers?" class="vc_gitem-link vc-zone-link"></a>.</p>
]]>
			</content:encoded>



		</item>
	</channel>
</rss>